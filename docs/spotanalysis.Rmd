---
title: "Cell/Spot Analysis"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

<style>
.title{
  display: none;
}
body {
  text-align: justify
}
.center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
</style>

```{css, echo=FALSE}
.watch-out {
  color: black;
}
```

```{r setup, include=FALSE}
# use rmarkdown::render_site(envir = knitr::knit_global())
knitr::opts_chunk$set(highlight = TRUE, echo = TRUE)
```

<br>

# MELC Data Analysis

VoltRon is an end-to-end spatial data analysis package which also supports investigating spatial points in single cell resolution. VoltRon includes essential built-in functions capable of **filtering**, **processing** and **clustering** as well as **visualizing** spatial datasets with a goal of cell type discovery and annotation. 

In this use case, we analyze segmented cells over microscopy images collected from **control** and **COVID-19** lung tissues of donors categorized based on disease durations (**control**, **acute**, **chronic** and **prolonged**). Each image is associated with one of few field of views (FOVs) from a single tissue section of a donor. See [GSE190732](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE190732) for more information. You can download the **IFdata.csv** file and the folder with the **DAPI** images [here](https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Cellanalysis/MELC/GSE190732.zip). 

We analyze cells characterized by **multi-epitope ligand cartography (MELC)** with a panel of 44 parameters. We use the already segmented cells on which expression of **43 protein features** (excluding DAPI) were mapped to these cells. 

We import the **protein intensities**, **metadata** and **coordinates** associated with segmented cells across FOVs of samples.

```{r eval = FALSE, class.source="watch-out"}
library(VoltRon)
IFdata <- read.csv("IFdata.csv")
data <- IFdata[,c(2:43)]
metadata <- IFdata[,c("disease_state", "object_id", "cluster", "Clusters",
                      "SourceID", "Sample", "FOV", "Section")]
coordinates <- as.matrix(IFdata[,c("posX","posY")], rownames.force = TRUE)
```

<br>

## Building VoltRon objects

First, we normalize the data using the hyperbolic arcsine function with a scale argument of 0.2.

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
data <- asinh(data/0.2)
```

Before analyzing MELC assays across FOVs, we should **build a VoltRon object** for each individual FOV/Section by using the **formVoltron** function. We then merge these sections to respective tissue blocks by defining their samples of origins. We can also define **assay names**, **assay types** and **sample (i.e. block) names** of these objects. 

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
library(dplyr)
library(magick)
vr_list <- list()
sample_metadata <- metadata %>% select(Sample, FOV, Section) %>% distinct()
for(i in 1:nrow(sample_metadata)){
  vrassay <- sample_metadata[i,]
  cells <- rownames(metadata)[metadata$Section == vrassay$Section]
  image <- image_read(paste0("DAPI/", vrassay$Sample, "/DAPI_", vrassay$FOV, ".tif"))
  vr_list[[vrassay$Section]] <- formVoltRon(data = t(data[cells,]), 
                                            metadata = metadata[cells,],
                                            image = image, 
                                            coords = coordinates[cells,],
                                            main.assay = "MELC", 
                                            assay.type = "cell",
                                            sample_name = vrassay$Section)
}
```

Before moving forward with merging sections, we should **flip coordinates** of cells and perhaps also then **resize** these images. The main reason for this coordinate flipping is that the y-axis of most digital images are of the opposite direction to the commonly used coordinate spaces. Hence, VoltRon offers the option to flip coordinates of spatial points with respect to the image using **flipCoordinates** function. 

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
for(i in 1:nrow(sample_metadata)){
  vrassay <- sample_metadata[i,]
  vr_list[[vrassay$Section]] <- flipCoordinates(vr_list[[vrassay$Section]])
  vr_list[[vrassay$Section]] <- resizeImage(vr_list[[vrassay$Section]], size = 600)
}
```

Finally, we merge these assays into one VoltRon object. The **samples** arguement in the merge function determines which assays are layers of a single tissue sample/block.

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
vr_merged <- merge(vr_list[[1]], vr_list[-1], samples = sample_metadata$Sample)
vr_merged 
```

```
VoltRon Object 
control_case_3: 
  Layers: Section1 Section2 
control_case_2: 
  Layers: Section1 Section2 
control_case_1: 
  Layers: Section1 Section2 Section3 
acute_case_3: 
  Layers: Section1 Section2 
acute_case_1: 
  Layers: Section1 Section2 
... 
There are 13 samples in total 
Assays: MELC(Main) 
```

<br>

## Dimensionality Reduction

Lets visualize some protein features on tissue sections. We can either use the DAPI images as a background (e.g. **background = image**), or select either "black" or "white" backgrounds (e.g. **background = "white"**).

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
vr_subset <- subset(vr_merged, samples = "control_case_1")
vrSpatialFeaturePlot(vr_subset, features = c("CollagenIV", "CD11b"), alpha = 1, pt.size = 0.7)
```

<img width="90%" height="90%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/cellspot_spatialfeature.png" class="center">

<br>

VoltRon is capable of reducing dimensionality of datasets using both PCA and UMAP which we gonna use to build neighborhood graphs and partition the data into cell types.  

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
vr_merged <- getPCA(vr_merged, dims = 10)
vr_merged <- getUMAP(vr_merged, dims = 1:10)
```

We can also visualize the normalized expression of these features on embedding spaces using **vrEmbeddingFeaturePlot** function. 

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
vrEmbeddingFeaturePlot(vr_merged, features = c("CollagenIV", "CD11b"), embedding = "umap")
```

<img width="100%" height="100%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/cellspot_embedding.png" class="center">

<br>

## Clustering

Next, we build neighborhood graphs with the **k-nearest neighbors of cells** which are constructed by dimensionally reduced gene expression profiles. We can conduct a clustering of cells using the **leiden's method** from the igraph package. 

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
vr_merged <- getProfileNeighbors(vr_merged, dims = 1:10, k = 10, method = "kNN")
vr_merged <- getClusters(vr_merged, resolution = 0.8, label = "MELC_Clusters")
```

Now we can visualize these clusters and perhaps also check for clusters that may reside in only specific disease conditions. 

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
library(patchwork)
vr_merged$Condition <- gsub("_[0-9]$", "", vr_merged$Sample)
g1 <- vrEmbeddingPlot(vr_merged, group.by = c("Condition"), embedding = "umap")
g2 <- vrEmbeddingPlot(vr_merged, group.by = c("MELC_Clusters"), embedding = "umap", 
                      label = TRUE)
g1 | g2
```

<img width="100%" height="100%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/cellspot_embeddingclusters.png" class="center">

<br>

## Visualization

VoltRon provides both violin plots (**vrViolinPlot**) and heatmaps (**vrHeatmapPlot**) to further investigate the enrichment of markers across newly clustered datasets. **Note:** the vrHeatmapPlot function would require you to have the **ComplexHeatmap** package in your namespace. 

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
library(ComplexHeatmap)
vrHeatmapPlot(vr_merged, features = vrFeatures(vr_merged), 
              group.by = "MELC_Clusters", show_row_names = TRUE)
```

<img width="100%" height="100%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/cellspot_heatmapclusters.png" class="center">

<br>

```{r eval = FALSE, class.source="watch-out", fig.align='center'}
vrViolinPlot(vr_merged, features = c("CD3", "SMA", "Pancytokeratin", "CCR2"), 
             group.by = "MELC_Clusters", ncol = 2)
```

<img width="100%" height="80%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/cellspot_violinclusters.png" class="center">

<br>

# Xenium Data Analysis

In this use case, we analyse **immunofluorescence (IF)** and **H&E images** of the **Xenium In Situ** and **Visium CytAssist** platforms readouts. Three tissue sections are derived from a single formalin-fixed, paraffin-embedded (FFPE) breast cancer tissue block. A 5 $\mu$m section was taken for Visium CytAssist and two replicate 5 $\mu$m sections were taken for the Xenium replicates. More information on the spatial datasets and the study can be also be found on the [BioArxiv preprint](https://www.biorxiv.org/content/10.1101/2022.10.06.510405v1).
 
In this use case, we will analyze the Xenium from the [10x Genomics website](https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast) (specifically, import **In Situ Replicate 1/2**). Alternatively, you can **download a zipped collection of Xenium readouts** from [here](https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/SpatialDataAlignment/Xenium_vs_Visium/10X_Xenium_Visium.zip). 

VoltRon includes built-in functions for converting readouts from both Xenium into VoltRon objects.

```{r eval = FALSE, class.source="watch-out"}
library(VoltRon)
Xen_R1 <- importXenium("Xenium_R1/outs", sample_name = "XeniumR1")
Xen_R2 <- importXenium("Xenium_R2/outs", sample_name = "XeniumR2")
```

Before moving on to the downstream analysis of the imaging-based data, we can inspect both Xenium images. We use the **vrImages** function to call and visualize reference images of all VoltRon objects. 

```{r eval = FALSE, class.source="watch-out"}
vrImages(Xen_R1)
vrImages(Xen_R2)
```

<table>
<tbody>
  <tr style = "vertical-align: center">
  <td style = "width:50%; vertical-align: center"> <img src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/xeniumr1.png" class="center"></td>
  <td style = "width:50%; vertical-align: center"> <img src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/xeniumr2.png" class="center"></td>
  </tr>
</tbody>
</table>

<br>

Although images of the first Xenium replicate and the Visium assay are workable, we have to adjust the brightness of the second Xenium replicate before image alignment. You can use **modulateImage** function to change the brightness and` saturation of the reference image of this VoltRon object. This functionality is optional for VoltRon objects and should be used when images require further adjustments. 

```{r eval = FALSE, class.source="watch-out"}
Xen_R2 <- modulateImage(Xen_R2, brightness = 800)
vrImages(Xen_R2)
```

<img width="40%" height="40%" src="https://bimsbstatic.mdc-berlin.de/landthaler/VoltRon/Package/images/xeniumr2_new.png" class="center">

<br>

Once both VoltRon objects are created and images are well-tuned, we can merge these two into a single VoltRon object. 

```{r eval = FALSE, class.source="watch-out"}
Xen_list <- list(Xen_R1, Xen_R2)
Xen_data <- merge(Xen_list[[1]], Xen_list[-1])
```

<br>

## Processing and Embedding 

Some number of cells in both Xenium images might have extremely low molecule counts. Although cells are detected at these locations, the low total counts of cells would make it hard for phenotyping and clustering these cells. Hence, we remove such cells from the VoltRon objects. Later, we can move on to normalizing the dataset to correct for count depth of cells, and conduct additional dimensionality reduction methods.

```{r eval = FALSE, class.source="watch-out"}
Xen_data <- subset(Xen_data, Count > 5)
Xen_data <- normalizeData(Xen_data)
Xen_data <- getPCA(Xen_data, dims = 20)
Xen_data <- getUMAP(Xen_data, dims = 1:20)
```

## Clustering

The **getProfileNeighbors** functions supports building graphs based on both k-nearest neighbors or **shared nearest neigbor** where edges between two cells represent the percentage of shared k-nearest neighbors between these two cells. Then, clustering is performed using the SNN graph. 

```{r eval = FALSE, class.source="watch-out"}
Xen_data <- getProfileNeighbors(Xen_data, dims = 1:10, k = 10, method = "SNN")
Xen_data <- getClusters(Xen_data, resolution = 1.0, label = "Clusters", graph = "SNN")
```

We can now visualize the clusters on both Xenium images, and query cell type markers.

```{r eval = FALSE, class.source="watch-out"}
vrSpatialPlot(Xen_data, group.by = "Clusters", pt.size = 0.4, background = "black")
vrSpatialFeaturePlot(Xen_data, features = c("ACTA2", "CCR7", "BANK1", "LRRC15"), pt.size = 0.4)
```

